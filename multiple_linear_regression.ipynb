{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Multiple Linear Regression - Codealong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea here is pretty simple. Whereas, in simple linear regression we took our dependent variable to be a function only of a single independent variable, here we'll be taking the dependent variable to be a function of multiple independent variables.\n",
    "\n",
    "Our regression equation, then, instead of looking like $\\hat{y} = mx + b$, will now look like:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + ... + \\hat{\\beta}_nx_n$.\n",
    "\n",
    "Remember that the hats ( $\\hat{}$ ) indicate parameters that are estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Categorical Variables\n",
    "\n",
    "One issue we'd like to resolve is what to do with categorical variables, i.e. variables that represent categories rather than continua. In a Pandas DataFrame, these columns may well have strings or objects for values, but they need not. Recall e.g. the heart-disease dataset from Kaggle in which the target variable took values 0-4, each representing a different stage of heart disease.\n",
    "\n",
    "### Dummying\n",
    "\n",
    "One very effective way of dealing with categorical variables is to dummy them out. What this involves is making a new column for _each categorical value in the column we're dummying out_. We'll do this below in our air safety dataset where we have a column of airline names.\n",
    "\n",
    "These new columns will be filled only with 0's and 1's, a 1 representing the presence of the relevant categorical value.\n",
    "\n",
    "Let's look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = pd.read_csv('../pandas-2/ds_chars.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>HP</th>\n",
       "      <th>home_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greg</td>\n",
       "      <td>200</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miles</td>\n",
       "      <td>200</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alan</td>\n",
       "      <td>170</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alison</td>\n",
       "      <td>300</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rachel</td>\n",
       "      <td>200</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name   HP home_state\n",
       "0    greg  200         WA\n",
       "1   miles  200         WA\n",
       "2    alan  170         TX\n",
       "3  alison  300         DC\n",
       "4  rachel  200         TX"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try using pd.get_dummies to create our dummy columns:\n",
    "\n",
    "\n",
    "# We could also have used LabelBinarizer from sklearn.preprocessing\n",
    "\n",
    "\n",
    "# Now we need to add these dummy columns to our original dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Use Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_csv('../../../../../data/drug-use-by-age/drug-use-by-age.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n</th>\n",
       "      <th>alcohol-use</th>\n",
       "      <th>alcohol-frequency</th>\n",
       "      <th>marijuana-use</th>\n",
       "      <th>marijuana-frequency</th>\n",
       "      <th>cocaine-use</th>\n",
       "      <th>cocaine-frequency</th>\n",
       "      <th>crack-use</th>\n",
       "      <th>crack-frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>oxycontin-use</th>\n",
       "      <th>oxycontin-frequency</th>\n",
       "      <th>tranquilizer-use</th>\n",
       "      <th>tranquilizer-frequency</th>\n",
       "      <th>stimulant-use</th>\n",
       "      <th>stimulant-frequency</th>\n",
       "      <th>meth-use</th>\n",
       "      <th>meth-frequency</th>\n",
       "      <th>sedative-use</th>\n",
       "      <th>sedative-frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2798</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2757</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2792</td>\n",
       "      <td>18.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2956</td>\n",
       "      <td>29.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3058</td>\n",
       "      <td>40.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age     n  alcohol-use  alcohol-frequency  marijuana-use  \\\n",
       "0  12  2798          3.9                3.0            1.1   \n",
       "1  13  2757          8.5                6.0            3.4   \n",
       "2  14  2792         18.1                5.0            8.7   \n",
       "3  15  2956         29.2                6.0           14.5   \n",
       "4  16  3058         40.1               10.0           22.5   \n",
       "\n",
       "   marijuana-frequency  cocaine-use cocaine-frequency  crack-use  \\\n",
       "0                  4.0          0.1               5.0        0.0   \n",
       "1                 15.0          0.1               1.0        0.0   \n",
       "2                 24.0          0.1               5.5        0.0   \n",
       "3                 25.0          0.5               4.0        0.1   \n",
       "4                 30.0          1.0               7.0        0.0   \n",
       "\n",
       "  crack-frequency        ...          oxycontin-use oxycontin-frequency  \\\n",
       "0               -        ...                    0.1                24.5   \n",
       "1             3.0        ...                    0.1                41.0   \n",
       "2               -        ...                    0.4                 4.5   \n",
       "3             9.5        ...                    0.8                 3.0   \n",
       "4             1.0        ...                    1.1                 4.0   \n",
       "\n",
       "   tranquilizer-use  tranquilizer-frequency  stimulant-use  \\\n",
       "0               0.2                    52.0            0.2   \n",
       "1               0.3                    25.5            0.3   \n",
       "2               0.9                     5.0            0.8   \n",
       "3               2.0                     4.5            1.5   \n",
       "4               2.4                    11.0            1.8   \n",
       "\n",
       "  stimulant-frequency  meth-use  meth-frequency  sedative-use  \\\n",
       "0                 2.0       0.0               -           0.2   \n",
       "1                 4.0       0.1             5.0           0.1   \n",
       "2                12.0       0.1            24.0           0.2   \n",
       "3                 6.0       0.3            10.5           0.4   \n",
       "4                 9.5       0.3            36.0           0.2   \n",
       "\n",
       "  sedative-frequency  \n",
       "0               13.0  \n",
       "1               19.0  \n",
       "2               16.5  \n",
       "3               30.0  \n",
       "4                3.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 28 columns):\n",
      "age                        17 non-null object\n",
      "n                          17 non-null int64\n",
      "alcohol-use                17 non-null float64\n",
      "alcohol-frequency          17 non-null float64\n",
      "marijuana-use              17 non-null float64\n",
      "marijuana-frequency        17 non-null float64\n",
      "cocaine-use                17 non-null float64\n",
      "cocaine-frequency          17 non-null object\n",
      "crack-use                  17 non-null float64\n",
      "crack-frequency            17 non-null object\n",
      "heroin-use                 17 non-null float64\n",
      "heroin-frequency           17 non-null object\n",
      "hallucinogen-use           17 non-null float64\n",
      "hallucinogen-frequency     17 non-null float64\n",
      "inhalant-use               17 non-null float64\n",
      "inhalant-frequency         17 non-null object\n",
      "pain-releiver-use          17 non-null float64\n",
      "pain-releiver-frequency    17 non-null float64\n",
      "oxycontin-use              17 non-null float64\n",
      "oxycontin-frequency        17 non-null object\n",
      "tranquilizer-use           17 non-null float64\n",
      "tranquilizer-frequency     17 non-null float64\n",
      "stimulant-use              17 non-null float64\n",
      "stimulant-frequency        17 non-null float64\n",
      "meth-use                   17 non-null float64\n",
      "meth-frequency             17 non-null object\n",
      "sedative-use               17 non-null float64\n",
      "sedative-frequency         17 non-null float64\n",
      "dtypes: float64(20), int64(1), object(7)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "drugs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs['age'] = drugs['age'].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at this 'age' column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = drugs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine that I'm going to try to predict age based on factors to do with drug use.\n",
    "\n",
    "Now: Which columns (predictors) should I choose? Even ignoring the non-numeric categories in my dataset, there are still 20 predictors I could choose! For each of these predictors, I could either use it or not use it in my model, which means that there are 2^20 = 1,048,576 different models I could construct! Well, okay, one of these is the \"empty model\" with no predictors in it. But there are still 1,048,575 models from which I can choose!\n",
    "\n",
    "How can I decide which predictors to use in my model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .corr() DataFrame method to find out about the\n",
    "# correlation values between all pairs of variables!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(8, 8)})\n",
    "\n",
    "# Use the .heatmap method to depict the relationships visually!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the correlations with 'age'\n",
    "# (our dependent variable) in particular.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drugs[['alcohol-use', 'tranquilizer-frequency', 'stimulant-use']]\n",
    "y = drugs['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity\n",
    "\n",
    "Probably 'alcohol-use' and 'alcohol-frequency' are highly correlated _with each other_ as well as with 'age'. This can lead to the production of an _overfit_ model. We'll stick a pin in this and return to the issue of overfit models soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression in StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdamico/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>age</td>       <th>  R-squared:         </th> <td>   0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   313.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>5.54e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:08:55</td>     <th>  Log-Likelihood:    </th> <td> 0.56922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   6.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   8.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   11.7667</td> <td>    0.352</td> <td>   33.440</td> <td> 0.000</td> <td>   10.906</td> <td>   12.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1241</td> <td>    0.014</td> <td>    8.887</td> <td> 0.000</td> <td>    0.090</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0018</td> <td>    0.015</td> <td>    0.116</td> <td> 0.911</td> <td>   -0.035</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0267</td> <td>    0.030</td> <td>   -0.894</td> <td> 0.406</td> <td>   -0.100</td> <td>    0.046</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.926</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.382</td> <th>  Jarque-Bera (JB):  </th> <td>   1.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.787</td> <th>  Prob(JB):          </th> <td>   0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.438</td> <th>  Cond. No.          </th> <td>    211.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    age   R-squared:                       0.994\n",
       "Model:                            OLS   Adj. R-squared:                  0.991\n",
       "Method:                 Least Squares   F-statistic:                     313.8\n",
       "Date:                Wed, 10 Apr 2019   Prob (F-statistic):           5.54e-07\n",
       "Time:                        14:08:55   Log-Likelihood:                0.56922\n",
       "No. Observations:                  10   AIC:                             6.862\n",
       "Df Residuals:                       6   BIC:                             8.072\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         11.7667      0.352     33.440      0.000      10.906      12.628\n",
       "x1             0.1241      0.014      8.887      0.000       0.090       0.158\n",
       "x2             0.0018      0.015      0.116      0.911      -0.035       0.039\n",
       "x3            -0.0267      0.030     -0.894      0.406      -0.100       0.046\n",
       "==============================================================================\n",
       "Omnibus:                        1.926   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.382   Jarque-Bera (JB):                1.163\n",
       "Skew:                           0.787   Prob(JB):                        0.559\n",
       "Kurtosis:                       2.438   Cond. No.                         211.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.asarray(X)\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "model = sm.OLS(y, predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdamico/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   258.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 08 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>2.77e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:33:43</td>     <th>  Log-Likelihood:    </th> <td> -3.1687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   12.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th> <td>   13.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   12.0290</td> <td>    0.234</td> <td>   51.464</td> <td> 0.000</td> <td>   11.476</td> <td>   12.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>meth-use</th>      <td>   -2.0819</td> <td>    1.227</td> <td>   -1.697</td> <td> 0.134</td> <td>   -4.983</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stimulant-use</th> <td>    2.4138</td> <td>    0.233</td> <td>   10.354</td> <td> 0.000</td> <td>    1.863</td> <td>    2.965</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.348</td> <th>  Durbin-Watson:     </th> <td>   1.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.510</td> <th>  Jarque-Bera (JB):  </th> <td>   0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.384</td> <th>  Prob(JB):          </th> <td>   0.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.799</td> <th>  Cond. No.          </th> <td>    27.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.987\n",
       "Model:                            OLS   Adj. R-squared:                  0.983\n",
       "Method:                 Least Squares   F-statistic:                     258.2\n",
       "Date:                Mon, 08 Apr 2019   Prob (F-statistic):           2.77e-07\n",
       "Time:                        11:33:43   Log-Likelihood:                -3.1687\n",
       "No. Observations:                  10   AIC:                             12.34\n",
       "Df Residuals:                       7   BIC:                             13.25\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const            12.0290      0.234     51.464      0.000      11.476      12.582\n",
       "meth-use         -2.0819      1.227     -1.697      0.134      -4.983       0.819\n",
       "stimulant-use     2.4138      0.233     10.354      0.000       1.863       2.965\n",
       "==============================================================================\n",
       "Omnibus:                        1.348   Durbin-Watson:                   1.806\n",
       "Prob(Omnibus):                  0.510   Jarque-Bera (JB):                0.847\n",
       "Skew:                          -0.384   Prob(JB):                        0.655\n",
       "Kurtosis:                       1.799   Cond. No.                         27.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.asarray(X2)\n",
    "predictors_int = sm.add_constant(X2)\n",
    "model = sm.OLS(np.asarray(y), predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a StandardScaler object to scale our data for us.\n",
    "\n",
    "\n",
    "\n",
    "# Now we'll apply it to our data by using the .fit_transform() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "# Now let's split our data into train and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the LinearRegression object to our training data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And score it on our testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the .coef_ attribute to recover the results\n",
    "# of the regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "The idea behind recursive feature elimination is to build up (or down) to a small set of predictive features slowly, by eliminating the features with the lowest coefficients.\n",
    "\n",
    "That is:\n",
    "1. Start with a model with _all_ $n$ predictors;\n",
    "2. find the predictor with the smallest coefficient;\n",
    "3. throw that predictor out and build a model with the remining $n-1$ predictors;\n",
    "4. set $n = n-1$ and repeat until $n-1$ has the value you want!\n",
    "\n",
    "### Recursive Feature Elimination in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr_rfe = LinearRegression()\n",
    "select = RFE(lr_rfe, n_features_to_select=2)\n",
    "select = select.fit(X = drugs.drop(columns=['age',\n",
    "                                       'cocaine-frequency',\n",
    "                                       'crack-frequency',\n",
    "                                       'heroin-frequency',\n",
    "                                       'inhalant-frequency',\n",
    "                                       'oxycontin-frequency',\n",
    "                                       'meth-frequency']),\n",
    "                    y = drugs['age'])\n",
    "\n",
    "select.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = drugs[['meth-use', 'stimulant-use']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Metrics\n",
    "\n",
    "The metrics module in sklearn has a number of metrics that we can use to meaure the accuracy of our model, including the $R^2$ score, the mean absolute error and the mean squared error. Note that the default 'score' on our model object is the $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726930605104313"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24770878321322107"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11529596673373455"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
